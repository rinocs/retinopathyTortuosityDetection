{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.0.1) C:\\ci\\opencv-suite_1573470242804\\work\\modules\\imgproc\\src\\color.cpp:181: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-52e2c75fbce0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sample/01_h.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m \u001b[0mgray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[0mkernel_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.0.1) C:\\ci\\opencv-suite_1573470242804\\work\\modules\\imgproc\\src\\color.cpp:181: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib.pyplot import imshow\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def image_resize(image, width = None, height = None, inter = cv2.INTER_AREA):\n",
    "    # initialize the dimensions of the image to be resized and\n",
    "    # grab the image size\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "\n",
    "    # if both the width and height are None, then return the\n",
    "    # original image\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "\n",
    "    # check to see if the width is None\n",
    "    if width is None:\n",
    "        # calculate the ratio of the height and construct the\n",
    "        # dimensions\n",
    "        r = height / float(h)\n",
    "        dim = (int(w * r), height)\n",
    "\n",
    "    # otherwise, the height is None\n",
    "    else:\n",
    "        # calculate the ratio of the width and construct the\n",
    "        # dimensions\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h * r))\n",
    "\n",
    "    # resize the image\n",
    "    resized = cv2.resize(image, dim, interpolation = inter)\n",
    "\n",
    "    # return the resized image\n",
    "    return resized\n",
    "\n",
    "img = cv2.imread('sample/01_h.png')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "kernel_size = 5\n",
    "blur_gray = cv2.GaussianBlur(gray,(kernel_size, kernel_size),0)\n",
    "cv2.imshow(\"gray\",blur_gray) \n",
    "cv2.waitKey()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_threshold = 1\n",
    "high_threshold = 150\n",
    "edges = cv2.Canny(blur_gray, low_threshold, high_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'NoneType' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-6de9c47bb79d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmin_line_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m  \u001b[1;31m# minimum number of pixels making up a line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmax_line_gap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m  \u001b[1;31m# maximum gap in pixels between connectable line segments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mline_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m0\u001b[0m  \u001b[1;31m# creating a blank to draw lines on\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Run Hough on edge detected image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "rho = 1  # distance resolution in pixels of the Hough grid\n",
    "theta = np.pi / 180  # angular resolution in radians of the Hough grid\n",
    "threshold = 15  # minimum number of votes (intersections in Hough grid cell)\n",
    "min_line_length = 50  # minimum number of pixels making up a line\n",
    "max_line_gap = 20  # maximum gap in pixels between connectable line segments\n",
    "line_image = np.copy(img) * 0  # creating a blank to draw lines on\n",
    "\n",
    "# Run Hough on edge detected image\n",
    "# Output \"lines\" is an array containing endpoints of detected line segments\n",
    "lines = cv2.HoughLinesP(edges, rho, theta, threshold, np.array([]),\n",
    "                    min_line_length, max_line_gap)\n",
    "\n",
    "for line in lines:\n",
    "    for x1,y1,x2,y2 in line:\n",
    "        cv2.line(line_image,(x1,y1),(x2,y2),(255,0,0),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.0.1) C:\\ci\\opencv-suite_1573470242804\\work\\modules\\core\\src\\arithm.cpp:663: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'cv::arithm_op'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-ac44818e5f94>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Draw the lines on the  image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlines_edges\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddWeighted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mline_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.0.1) C:\\ci\\opencv-suite_1573470242804\\work\\modules\\core\\src\\arithm.cpp:663: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'cv::arithm_op'\n"
     ]
    }
   ],
   "source": [
    "# Draw the lines on the  image\n",
    "lines_edges = cv2.addWeighted(img, 0.8, line_image, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow(\"final\",lines_edges)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2336, 3504, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "#from poly_point_isect import isect_segments_bentley_ottmann as bot\n",
    "#import isect_segments_bentley_ottmann.poly_point_isect as bot\n",
    "import poly_point_isect as bot\n",
    "\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "kernel_size = 5\n",
    "blur_gray = cv2.GaussianBlur(gray,(kernel_size, kernel_size),0)\n",
    "\n",
    "# cv2.imshow(\"blur_gray\",blur_gray)\n",
    "\n",
    "# cv2.imshow(\"edges\",edges)\n",
    "mask = blur_gray\n",
    "height,width = mask.shape\n",
    "skel = np.zeros([height,width],dtype=np.uint8)      #[height,width,3]\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (3,3))\n",
    "temp_nonzero = np.count_nonzero(mask)\n",
    "while(np.count_nonzero(mask) != 0 ):\n",
    "    eroded = cv2.erode(mask,kernel)\n",
    "#     cv2.imshow(\"eroded\",eroded)   \n",
    "#     cv2.waitKey()\n",
    "    temp = cv2.dilate(eroded,kernel)\n",
    "#     cv2.imshow(\"dilate\",temp)\n",
    "#     cv2.waitKey()\n",
    "    temp = cv2.subtract(mask,temp)\n",
    "    skel = cv2.bitwise_or(skel,temp)\n",
    "    mask = eroded.copy()\n",
    "\n",
    "low_threshold = 50\n",
    "high_threshold = 150\n",
    "edges = cv2.Canny(blur_gray, low_threshold, high_threshold)\n",
    "   \n",
    "cv2.imshow(\"edges\",edges)\n",
    "cv2.waitKey()\n",
    "\n",
    "\n",
    "rho = 1  # distance resolution in pixels of the Hough grid\n",
    "theta = np.pi / 180  # angular resolution in radians of the Hough grid\n",
    "threshold = 15  # minimum number of votes (intersections in Hough grid cell)\n",
    "min_line_length = 50  # minimum number of pixels making up a line\n",
    "max_line_gap = 20  # maximum gap in pixels between connectable line segments\n",
    "line_image = np.copy(img) * 0  # creating a blank to draw lines on\n",
    "new_image = np.copy(img) * 0 \n",
    "# Run Hough on edge detected image\n",
    "# Output \"lines\" is an array containing endpoints of detected line segments\n",
    "lines = cv2.HoughLinesP(edges, rho, theta, threshold, np.array([]),min_line_length, max_line_gap)\n",
    "#print(lines)\n",
    "points = []\n",
    "for line in lines:\n",
    "    for x1, y1, x2, y2 in line:\n",
    "        points.append(((x1 + 0.0, y1 + 0.0), (x2 + 0.0, y2 + 0.0)))\n",
    "        cv2.line(line_image, (x1, y1), (x2, y2), (255, 0, 0), 5)\n",
    "\n",
    "\n",
    "lines_edges = cv2.addWeighted(new_image, 0.8, line_image, 1, 0)\n",
    "print(lines_edges.shape)\n",
    "\n",
    "\n",
    "# print(points)\n",
    "intersections = bot.isect_segments(points)\n",
    "# print(intersections)\n",
    "# for idx, inter in enumerate(intersections):\n",
    "#     a, b = inter\n",
    "#     match = 0\n",
    "#     for other_inter in intersections[idx:]:\n",
    "#         c, d = other_inter\n",
    "#         if abs(c-a) < 15 and abs(d-b) < 15:\n",
    "#             match = 1\n",
    "#             intersections[idx] = ((c+a)/2, (d+b)/2)\n",
    "#             intersections.remove(other_inter)\n",
    "\n",
    "#     if match == 0:\n",
    "#         intersections.remove(inter)\n",
    "        \n",
    "for inter in intersections:\n",
    "    a, b = inter\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            lines_edges[int(b) + i, int(a) + j] = [0, 255, 0]\n",
    "\n",
    "cv2.imshow('lines_edges',lines_edges)\n",
    "cv2.imshow('img',img)\n",
    "cv2.imshow(\"skel\",skel)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('sample/01_h.tif')\n",
    "# convert image to grayscale\n",
    "small1 = cv2.resize(img, (0,0), fx=0.5, fy=0.5) \n",
    "gray = cv2.cvtColor(small1, cv2.COLOR_BGR2GRAY)\n",
    "gray = np.float32(gray)\n",
    "\n",
    "'''\n",
    "args:\n",
    "img - Input image, it should be grayscale and float32 type.\n",
    "blockSize - It is the size of neighbourhood considered for corner detection\n",
    "ksize - Aperture parameter of Sobel derivative used.\n",
    "k - Harris detector free parameter in the equation.\n",
    "'''\n",
    "dst = cv2.cornerHarris(gray, 9, 5, 0.04)\n",
    "# result is dilated for marking the corners\n",
    "dst = cv2.dilate(dst,None)\n",
    "\n",
    "# Threshold for an optimal value, it may vary depending on the image.\n",
    "img_thresh = cv2.threshold(dst, 0.32*dst.max(), 255, 0)[1]\n",
    "img_thresh = np.uint8(img_thresh)\n",
    "\n",
    "# get the matrix with the x and y locations of each centroid\n",
    "centroids = cv2.connectedComponentsWithStats(img_thresh)[3]\n",
    "\n",
    "\n",
    "stop_criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "# refine corner coordinates to subpixel accuracy\n",
    "corners = cv2.cornerSubPix(gray, np.float32(centroids), (5,5), (-1,-1), stop_criteria)\n",
    "for i in range(1, len(corners)):\n",
    "    #print(corners[i])\n",
    "    cv2.circle(small1, (int(corners[i,0]), int(corners[i,1])), 5, (0,255,0), 2)\n",
    "\n",
    "\n",
    "\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('sample/01_h.tif')\n",
    "# convert image to grayscale\n",
    "# small = cv2.resize(img, (0,0), fx=0.3, fy=0.3) \n",
    "small = image_resize(img, height = 1080)\n",
    "gray = cv2.cvtColor(small, cv2.COLOR_BGR2GRAY)\n",
    "gray = np.float32(gray)\n",
    "\n",
    "'''\n",
    "args:\n",
    "img - Input image, it should be grayscale and float32 type.\n",
    "blockSize - It is the size of neighbourhood considered for corner detection\n",
    "ksize - Aperture parameter of Sobel derivative used.\n",
    "k - Harris detector free parameter in the equation.\n",
    "'''\n",
    "dst = cv2.cornerHarris(gray, 9, 5, 0.04)\n",
    "# result is dilated for marking the corners\n",
    "dst = cv2.dilate(dst,None)\n",
    "\n",
    "# Threshold for an optimal value, it may vary depending on the image.\n",
    "img_thresh = cv2.threshold(dst, 0.32*dst.max(), 255, 0)[1]\n",
    "img_thresh = np.uint8(img_thresh)\n",
    "\n",
    "# get the matrix with the x and y locations of each centroid\n",
    "centroids = cv2.connectedComponentsWithStats(img_thresh)[3]\n",
    "\n",
    "\n",
    "stop_criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "# refine corner coordinates to subpixel accuracy\n",
    "corners = cv2.cornerSubPix(gray, np.float32(centroids), (5,5), (-1,-1), stop_criteria)\n",
    "for i in range(1, len(corners)):\n",
    "    #print(corners[i])\n",
    "    cv2.circle(small, (int(corners[i,0]), int(corners[i,1])), 5, (0,255,0), 2)\n",
    "\n",
    "cv2.imshow('img1', small)\n",
    "# cv2.imshow('img', small1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('sample/vessel1.png')\n",
    "# convert image to grayscale\n",
    "# small = cv2.resize(img, (0,0), fx=0.3, fy=0.3) \n",
    "small = image_resize(img, height = 1080)\n",
    "gray = cv2.cvtColor(small, cv2.COLOR_BGR2GRAY)\n",
    "gray = np.float32(gray)\n",
    "\n",
    "def detect(img):\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        harris_cv = cv2.goodFeaturesToTrack(gray, **harris_params)\n",
    "\n",
    "        for c in harris_cv:\n",
    "            cv2.circle(img, (int(c[0,0]), int(c[0,1])), 8, (0,0,255))\n",
    "\n",
    "        cv2.imshow(\"prova\",img)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "harris_params = dict(maxCorners = 500,\n",
    "                     qualityLevel = 0.03,\n",
    "                     minDistance = 11,\n",
    "                     blockSize = 11,\n",
    "                     useHarrisDetector = True)\n",
    "\n",
    "detect(small)\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
